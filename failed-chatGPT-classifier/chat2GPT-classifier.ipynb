{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "training_data = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "valitdation_data = load_dataset(\"financial_phrasebank\", \"sentences_75agree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 15:21:53.902361: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 15:21:54.024139: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-29 15:21:54.024170: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-29 15:21:54.024599: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-29 15:21:54.087447: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 15:21:54.928721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_function at 0x7f8fdd1fb6d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a13bd51447a42ae811bf14362d9e9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import  TFGPT2Tokenizer\n",
    "\n",
    "tokenizer =  TFGPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"])\n",
    "\n",
    "train_tokens = training_data.map(preprocess_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581ce86beed442e4be7b11f9a9546e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'attention_mask', 'input_ids'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tokens = valitdation_data.map(preprocess_function)\n",
    "val_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "batches_per_epoch = len(train_tokens[\"train\"]) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)\n",
    "\n",
    "batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .', 'label': 1, 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [4821, 284, 17113, 837, 262, 1664, 468, 645, 3352, 284, 1445, 477, 3227, 284, 3284, 837, 3584, 326, 318, 810, 262, 1664, 318, 3957, 764]}\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"negative\", 2: \"positive\", 1: \"neutral\"}\n",
    "label2id = {\"negative\": 0, \"positive\": 2,\"neutral\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2ForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFGPT2ForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import  TFGPT2ForSequenceClassification\n",
    "\n",
    "model =  TFGPT2ForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\", num_labels=3, id2label=id2label, label2id=label2id, problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntf_validation_set= model.prepare_tf_dataset(\\n\\n    val_tokens[\"train\"],\\n\\n    shuffle=True,\\n\\n    batch_size=1,\\n)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "\n",
    "    train_tokens[\"train\"],\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "tf_validation_set= model.prepare_tf_dataset(\n",
    "\n",
    "    val_tokens[\"train\"],\n",
    "\n",
    "    shuffle=True,\n",
    "\n",
    "    batch_size=1,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=({'attention_mask': TensorSpec(shape=(1, None), dtype=tf.int64, name=None), 'input_ids': TensorSpec(shape=(1, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(1,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(optimizer=optimizer)  # No loss argument!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63756d9e99f04832b8c3b0a4aeaec970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gm/Documents/unb-course/NLP/chat2Fsentiment is already a clone of https://huggingface.co/Dave12121/chat2Fsentiment. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PushToHubCallback\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"chat2Fsentiment\", tokenizer=tokenizer, hub_model_id=\"Dave12121/chat2Fsentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "callbacks = [push_to_hub_callback]\n",
    "\n",
    "## Cannot handle batch sizse bigger then one if no padding token is defiened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 0.6606"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TFGPT2Tokenizer' object has no attribute 'save_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_train_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/keras_callbacks.py:377\u001b[0m, in \u001b[0;36mPushToHubCallback.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint:\n\u001b[1;32m    379\u001b[0m     checkpoint_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TFGPT2Tokenizer' object has no attribute 'save_pretrained'"
     ]
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, callbacks=callbacks,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': <tf.Tensor: shape=(45,), dtype=int32, numpy=\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1], dtype=int32)>,\n",
       " 'input_ids': <tf.Tensor: shape=(45,), dtype=int32, numpy=\n",
       " array([  464,  1664,   991, 13423,   663, 25079,   287,  3050,   284,\n",
       "         4622,  2620,   422,   262,  1241,   286,  3717,   837,  4375,\n",
       "          326,  7559,  1910,  4331,  1799,   318,   991,  1165,  3595,\n",
       "          329, 34412, 26119,   319,   262,  1910,  2478,   286,   262,\n",
       "         2775,  9138,  1597,  1141,   262,  1459,   614, 10148,   764],\n",
       "       dtype=int32)>}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample =  \"The company still expects its turnover in 2010 to slightly increase from the level of 2009 , adding that `` market predictability is still too poor for trustworthy forecasts on the market development of the contract manufacturing business during the current year '' .\"\n",
    "#@positive \n",
    "\n",
    "\n",
    "res = tokenizer(sample)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.4324854   3.0709777  -0.40611345]\n",
      " [-2.4569297   8.503071   -1.7715104 ]\n",
      " [-3.3441517   9.665132   -2.3678463 ]\n",
      " [-1.8486593   6.0433984  -1.1951487 ]\n",
      " [-2.1100042   9.485331   -1.5617089 ]\n",
      " [-1.791574    6.8757706  -0.5577465 ]\n",
      " [-1.8085469   8.50463    -1.4421874 ]\n",
      " [-1.4257947   4.8182955  -0.57911605]\n",
      " [-2.3357275   9.129903   -1.8939478 ]\n",
      " [-2.0574517   9.119795   -1.3780642 ]\n",
      " [-2.4704866   8.949904   -0.86589247]\n",
      " [-2.8590393  11.990199   -1.5792216 ]\n",
      " [-1.851683   10.738962   -1.3899277 ]\n",
      " [-2.6057053   8.11302    -1.1163359 ]\n",
      " [-2.7843194  12.061036   -1.5193974 ]\n",
      " [-1.5283071   5.541763   -0.18603367]\n",
      " [-2.378657   10.171539   -0.7288166 ]\n",
      " [-1.8800042   8.486394   -1.0343827 ]\n",
      " [-2.2138212   8.6564455  -1.4366947 ]\n",
      " [-2.2832594   9.216361   -0.17686924]\n",
      " [-1.0274462   8.656375   -0.5509918 ]\n",
      " [-1.3884641   6.5475698  -0.3847338 ]\n",
      " [-1.976958    7.039391   -1.4013064 ]\n",
      " [-2.5766757  11.581657   -2.0108888 ]\n",
      " [-2.2498922  11.48768    -2.006533  ]\n",
      " [-2.0672467  12.002704   -1.5658185 ]\n",
      " [-1.5607749   5.192803   -0.54625106]\n",
      " [-1.7669227   9.43657    -1.2689433 ]\n",
      " [-2.0614846   9.812859   -1.161436  ]\n",
      " [-1.8608668   6.1569576  -0.3825578 ]\n",
      " [-1.6270001   8.888146   -1.1554662 ]\n",
      " [-1.778752   11.01339    -1.5807911 ]\n",
      " [-1.089961    6.561909   -0.62633693]\n",
      " [-1.4344833   8.251596   -0.9171009 ]\n",
      " [-1.7699108   8.964069   -1.3976693 ]\n",
      " [-1.7769885  10.386495   -1.5894017 ]\n",
      " [-0.92542946  8.663432   -0.4835301 ]\n",
      " [-1.469603    9.765147   -1.1937077 ]\n",
      " [-1.4023294   7.13019    -0.61664397]\n",
      " [-1.1820982   7.666298   -0.86644953]\n",
      " [-1.5090257  10.074773   -1.5159522 ]\n",
      " [-1.7723314  10.146279   -1.6751904 ]\n",
      " [-0.8487037   5.246148   -0.42999363]\n",
      " [-0.8276231   4.152731    0.0773699 ]\n",
      " [-0.38422334  7.197484    0.02892252]], shape=(45, 3), dtype=float32)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "result = model({\"input_ids\": res['input_ids'], \"attention_mask\": tf.expand_dims(res['attention_mask'], axis=0)}).logits\n",
    "\n",
    "print(result)\n",
    "\n",
    "predicted_class_id = int(tf.math.argmax(result, axis=-1)[0])\n",
    "\n",
    "print(predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"chatGPT2-instance\", from_tf=True)\n",
    "#tokenizer.save_pretrained(\"chatGPT\", from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"chatGPT2-instance-nontf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
