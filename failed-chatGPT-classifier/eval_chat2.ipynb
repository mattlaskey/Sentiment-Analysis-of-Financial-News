{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55b6206-b656-4f8c-95aa-5de01fb818ae",
   "metadata": {},
   "source": [
    "# Evaluation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22125b49-2b7d-446b-b3eb-b86df3ab0707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5e67955ecd4bc8b5ab1dbf3b1695d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89341281680b43baa339fa347e502c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2ForSequenceClassification.\n",
      "\n",
      "All the layers of TFGPT2ForSequenceClassification were initialized from the model checkpoint at Dave12121/chat2Fsentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2ForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFGPT2ForSequenceClassification\n",
    "\n",
    "from transformers import  TFGPT2Tokenizer\n",
    "\n",
    "tokenizer =  TFGPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = TFGPT2ForSequenceClassification.from_pretrained(\"Dave12121/chat2Fsentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9264cdf-6e8e-4076-8b4c-2eeaf54bcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9739cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sentences_75 = load_dataset(\"financial_phrasebank\", \"sentences_75agree\")\n",
    "print(sentences_75[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff54e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "refLabels = []\n",
    "for i in sentences_75['train']:\n",
    "    refLabels.append(i['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19baf62c-3390-420f-a748-0a9ef91c54c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predLabels = []\n",
    "i = 1\n",
    "for x in sentences_75[\"train\"]:\n",
    "    sample = x['sentence']\n",
    "    res = tokenizer(sample)\n",
    "    result = model({\"input_ids\": res['input_ids'], \"attention_mask\": tf.expand_dims(res['attention_mask'], axis=0)}).logits\n",
    "    predicted_class_id = int(tf.math.argmax(result, axis=-1)[0])\n",
    "    predLabels.append(predicted_class_id)\n",
    "    i += 1\n",
    "    if (i % 100) == 0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3ba481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.10500039370026198}\n",
      "{'f1': 0.2568780770344628}\n",
      "{'f1': 0.13625192012288787}\n",
      "{'f1': array([0.        , 0.        , 0.40875576])}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "#1 neutral 2 positive\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "print(f1.compute(predictions = predLabels, references = refLabels, average = 'weighted'))\n",
    "print(f1.compute(predictions = predLabels, references = refLabels, average = 'micro'))\n",
    "print(f1.compute(predictions = predLabels, references = refLabels, average = 'macro'))\n",
    "print(f1.compute(predictions = predLabels, references = refLabels, average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a7c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
